{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectif:\n",
    "- **Développer un modèle de Machine Learning, permettant d'estimer le poids d'un crâne en fonction de son volume**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importer les librairies pour lire, explorer et manipuler les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignorer les méssages d'avertissements\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation et exploration  des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('headbrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape) # Format de la source (nombre de lignes, nombre de colonnes)\n",
    "data.info()       # Affiche des  informations sur les données\n",
    "data.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sélection des champs utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Gender', 'Age Range'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Détection des données dupliquées, manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comptage du nombre de ligne duppiquées\n",
    "print (\"Nombre de données dupliquées:\", data.duplicated().sum())\n",
    "# Détection des valeurs manquantes\n",
    "print (\"Nombre de données manquantes:\\n\", data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Détection des données aberrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(10,5),gridspec_kw={'wspace': 0.3})\n",
    "sns.boxplot(data['Head Size(cm^3)'], ax = axs[0])\n",
    "sns.boxplot(data['Brain Weight(grams)'], ax = axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse de la relation entre les deux variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data['Head Size(cm^3)'], data['Brain Weight(grams)']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Détection des valeurs aberante dans X=Head Size(cm^3) par la methode IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Premier et Troisième quartile de la variable Head Size(cm^3)\n",
    "Q1 = data['Head Size(cm^3)'].quantile(0.25)\n",
    "Q3 = data['Head Size(cm^3)'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "minimum = Q1 - 1.5*IQR\n",
    "maximum= Q3 + 1.5*IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Les valeurs aberrantes de la variable: Head Size(cm^3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_Head = data[(data['Head Size(cm^3)']<minimum)|(data['Head Size(cm^3)']>maximum)]\n",
    "outlier_Head.shape, outlier_Head.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_Head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Détection des valeurs aberante dans y= Brain Weight(grams) par la methode IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data['Brain Weight(grams)'].quantile(0.25)\n",
    "Q3 = data['Brain Weight(grams)'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "minimum = Q1 - 1.5*IQR\n",
    "maximum = Q3 + 1.5*IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Les valeurs aberantes dans la variable: Brain Weight(grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_Brain= data[(data['Brain Weight(grams)']<minimum)|(data['Brain Weight(grams)']>maximum)]\n",
    "outliers_Brain.shape, outliers_Brain.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_Brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataFrame des valeurs aberrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = pd.concat([outlier_Head, outliers_Brain])\n",
    "outliers.shape, outliers.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppréssion des doublons\n",
    "outliers= outliers.drop_duplicates()\n",
    "outliers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppression des données aberrantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nettoye = data.drop(outliers.index)\n",
    "data_nettoye.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importer les librairies pour la modélisation les testes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer une base de test et une base d'apprentissage\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# Importer la classe LinearRegression\n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "#Importer les metriques pour tester le modèle\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diviser la base en un ensemble d'apprentissage et un ensemble de test (par defaut 75 % pour l'apprentissage et 25% pour le test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable d'entrée (explicative)\n",
    "X= data[['Head Size(cm^3)']] \n",
    "# Variable de sortie à expliquer\n",
    "y= data[['Brain Weight(grams)']] \n",
    "\n",
    "# Création d'une base d'apprentissage et d'une base de test\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.30, random_state = 42)\n",
    "X_train.shape , y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recherche du modèle y = a*X +b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle\n",
    "rl = LinearRegression()\n",
    "# Apprentissage du modèle utilisant la base d'apprentissage\n",
    "rl.fit(X_train,y_train)\n",
    "# Estimation de y utilisant la base de test \n",
    "y_pred = rl.predict(X_test)\n",
    "\n",
    "#Calcul des paramètres du modèle\n",
    "a = rl.coef_   \n",
    "b = rl.intercept_\n",
    "print (\"a=\", a)\n",
    "print(\"b=\", b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualité du modèle developé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('Metrics.PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clacul de MAE, MSE, RMSE, R et R²\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred) # Calcul l'erreur absolue moyenne\n",
    "mse = mean_squared_error(y_test, y_pred) # Calcul l’erreur quadratique moyenne\n",
    "rmse = np.sqrt(mse) #Racine carrée de l’erreur quadratique moyenne\n",
    "r2_score = rl.score(X_test, y_test) # Calcule de R²\n",
    "r_score = np.sqrt(r2_score) # Calcul de R\n",
    "print (\"MAE=\", mae)\n",
    "print (\"MSE=\", mse)\n",
    "print(\"RMSE=\" , np.sqrt(mse))\n",
    "print(\"R= \", r_score)\n",
    "print(\"R²= \", r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modélisation  sans les valeurs aberantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data_nettoye[['Head Size(cm^3)']] # Variable d'entrée (explicative)\n",
    "y= data_nettoye[['Brain Weight(grams)']] # Variable de sortie à expliquer\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle\n",
    "rl = LinearRegression()\n",
    "# Apprentissage du modèle utilisant la base d'apprentissage\n",
    "rl.fit(X_train,y_train)\n",
    "# Estimation de y utilisant le modèle developpé\n",
    "y_pred = rl.predict(X_test)\n",
    "\n",
    "#Calcul des paramètres du modèle\n",
    "a = rl.coef_   \n",
    "b = rl.intercept_\n",
    "print (\"a=\", a)\n",
    "print(\"b=\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clacul de MAE, MSE, RMSE, R et R²\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred) # Calcul l'erreur absolue moyenne\n",
    "mse = mean_squared_error(y_test, y_pred) # Calcul l’erreur quadratique moyenne\n",
    "rmse = np.sqrt(mse) #Racine carrée de l’erreur quadratique moyenne\n",
    "r2_score = rl.score(X_test, y_test) # Calcule de R²\n",
    "r_score = np.sqrt(r2_score) # Calcul de R\n",
    "print (\"MAE=\", mae)\n",
    "print (\"MSE=\", mse)\n",
    "print(\"RMSE=\" , np.sqrt(mse))\n",
    "print(\"R= \", r_score)\n",
    "print(\"R²= \", r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression lineaire multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectif:\n",
    "- **Développer un modèle de Machine Learning, permettant d'estimer les ventes en fonction de plusieurs variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importer et explorer  la source de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Advertising.csv')\n",
    "print(df.shape) # Format de la source (nombre de lignes, nombre de colonnes)\n",
    "df.info()       # Affiche des  informations sur les données\n",
    "df.head()       # Affiche les 5 premiers enregistrements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Détection des valeurs manquantes, aberrantes, des doublons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comptage du nombre de ligne duppiquées\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Détection des valeurs manquantes\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2,figsize=(10,8),gridspec_kw={'hspace': 0.2, 'wspace': 0.2})\n",
    "sns.boxplot(df['TV'], ax = axs[0][0])\n",
    "sns.boxplot(df['radio'], ax = axs[0][1])\n",
    "sns.boxplot(df['newspaper'], ax = axs[1][0])\n",
    "sns.boxplot(df['sales'], ax = axs[1][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyse des correlations entre les variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, diag_kind = 'kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matrice de correlation\n",
    "Mat_Corr = df.corr()\n",
    "Mat_Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(Mat_Corr, \n",
    "            xticklabels=Mat_Corr.columns,\n",
    "            yticklabels=Mat_Corr.columns,\n",
    "            cmap='RdBu_r',\n",
    "            annot=True,\n",
    "            linewidth=0.7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diviser la base en un ensemble d'apprentissage et un ensemble de test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df[['TV', 'radio', 'newspaper']] # Les variables d'entrées\n",
    "Xr=df[['TV', 'radio']] # Les variables d'entrées sans la variable newspaper\n",
    "y= df[['sales']] # La variable de sortie\n",
    "\n",
    "#Les ensembles d'apprentisssage et de test avec tous les variables\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.30, random_state = 42)\n",
    "#Les ensembles d'apprentisssage et de test sans la variable newspaper\n",
    "Xr_train, Xr_test, yr_train, yr_test = model_selection.train_test_split(Xr, y, test_size = 0.30, random_state = 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape , y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xr_train.shape , yr_train.shape, Xr_test.shape, yr_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recherche des modèles;\n",
    "- Sales = a0+ a1 * TV + a2 * radio + a3 * newspaper\n",
    "- Sales_r = a0+ a1 * TV + a2 * radio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des modèles\n",
    "lr1 = LinearRegression()\n",
    "lr2 = LinearRegression()\n",
    "\n",
    "# Apprentissage du modèle utilisant la base d'apprentissage\n",
    "lr1.fit(X_train,y_train)\n",
    "# Apprentissage du modèle utilisant la base d'apprentissage (sans la variable newspaper)\n",
    "lr2.fit(Xr_train,yr_train)\n",
    "\n",
    "# Estimation de y modèle entier\n",
    "y_pred = lr1.predict(X_test)\n",
    "# Estimation de y modèle réduit\n",
    "yr_pred = lr2.predict(Xr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcul des paramètres du modèle entier\n",
    "print('Les paramètre du modèle entier:')\n",
    "print('-------------------------------------\\n')\n",
    "a0 = lr1.intercept_   \n",
    "a1 = lr1.coef_[0][0]\n",
    "a2 = lr1.coef_[0][1]\n",
    "a3 = lr1.coef_[0][2]\n",
    "print(\"a0=\", a0)\n",
    "print(\"a1=\", a1)\n",
    "print(\"a2=\", a2)\n",
    "print(\"a3=\", a3)\n",
    "print('\\nLes paramètre du modèle sans la variable newspapers:')\n",
    "print('---------------------------------------------------------')\n",
    "#Calcul des paramètres du modèle réduit\n",
    "a0_r = lr2.intercept_   \n",
    "a1_r = lr2.coef_[0][0]\n",
    "a2_r = lr2.coef_[0][1]\n",
    "print(\"a0_r=\", a0_r)\n",
    "print(\"a1_r=\", a1_r)\n",
    "print(\"a2_r=\", a2_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualité des modèles developés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clacul de MAE, MSE, RMSE, R et R² pour le modèle entier\n",
    "\n",
    "print(\"Qualité du modèle entier:\")\n",
    "print('-------------------------------------')\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2_score = lr1.score(X_test, y_test)\n",
    "r_score = np.sqrt(r2_score)\n",
    "print (\"MAE=\", mae)\n",
    "print (\"MSE=\", mse)\n",
    "print(\"RMSE=\" , np.sqrt(mse))\n",
    "print(\"R= \", r_score)\n",
    "print(\"R²= \", r2_score)\n",
    "\n",
    "# Clacul de MAE, MSE, RMSE, R et R² pour le modèle réduit\n",
    "print(\"\\nQualité du modèle réduit:\")\n",
    "print('-------------------------------------')\n",
    "mae = mean_absolute_error(yr_test, yr_pred)\n",
    "mse = mean_squared_error(yr_test, yr_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2_score = lr2.score(Xr_test, yr_test)\n",
    "r_score = np.sqrt(r2_score)\n",
    "print (\"MAE_r=\", mae)\n",
    "print (\"MSE_r=\", mse)\n",
    "print(\"RMSE_r=\" , np.sqrt(mse))\n",
    "print(\"R= \", r_score)\n",
    "print(\"R²= \", r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autres modèles de régression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle de régression utilisant  Les arbres de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation de la librairie\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df[['TV', 'radio', 'newspaper']] # Les variables d'entrées\n",
    "y= df[['sales']] # La variable de sortie\n",
    "\n",
    "#Les ensembles d'apprentisssage et de test avec tous les variables\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Modélisation\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train,y_train)\n",
    "pred_tree= tree.predict(X_test)\n",
    "\n",
    "# Clacul de MAE, MSE, RMSE, R et R² \n",
    "\n",
    "mae_TREE = mean_absolute_error(y_test, pred_tree)\n",
    "mse_TREE = mean_squared_error(y_test, pred_tree)\n",
    "rmse_TREE= np.sqrt(mse_TREE)\n",
    "r2_score = tree.score(X_test, y_test)\n",
    "r_score = np.sqrt(r2_score)\n",
    "print (\"MAE Modèle TREE=\", mae_TREE)\n",
    "print (\"MSE Modèle TREE=\", mse_TREE)\n",
    "print(\"RMSE Modèle TREE=\" , rmse_TREE)\n",
    "print(\"R= \", r_score)\n",
    "print(\"R²= \", r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle de régression utilisant  Les forêts aléatoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('RF_Regressor.PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()# 100 arbres, valeur par défaut\n",
    "rf.fit(X_train,y_train)\n",
    "pred_rf= rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clacul de MAE, MSE, RMSE, R et R² \n",
    "\n",
    "mae_RF_100 = mean_absolute_error(y_test, pred_rf)\n",
    "mse_RF_100= mean_squared_error(y_test, pred_rf)\n",
    "rmse_RF_100 = np.sqrt(mse_RF_100)\n",
    "r2_score = rf.score(X_test, y_test)\n",
    "r_score = np.sqrt(r2_score)\n",
    "print (\"MAE RF(100 arbres) =\", mae_RF_100)\n",
    "print (\"MSE RF(100 arbres) =\", mse_RF_100)\n",
    "print(\"RMSE RF (100 arbres) =\" ,rmse_RF_100)\n",
    "print(\"R= \", r_score)\n",
    "print(\"R²= \", r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
